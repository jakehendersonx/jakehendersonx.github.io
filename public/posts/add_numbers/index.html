<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Neural Network Intuition: A Neural Network that Adds Two Numbers in PyTorch | None() to Some()</title>
<meta name=keywords content="neural network,machine learning,pytorch"><meta name=description content="writing a nn that adds two numbers in pytorch and comparing with the first response of flagship AI models"><meta name=author content="Jake Henderson"><link rel=canonical href=https://canonical.url/to/page><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/add_numbers/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/add_numbers/"><meta property="og:site_name" content="None() to Some()"><meta property="og:title" content="Neural Network Intuition: A Neural Network that Adds Two Numbers in PyTorch"><meta property="og:description" content="writing a nn that adds two numbers in pytorch and comparing with the first response of flagship AI models"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-09-15T11:30:03+00:00"><meta property="article:modified_time" content="2020-09-15T11:30:03+00:00"><meta property="article:tag" content="Neural Network"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Pytorch"><meta property="og:image" content="http://localhost:1313/%3Cimage%20path/url%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Cimage%20path/url%3E"><meta name=twitter:title content="Neural Network Intuition: A Neural Network that Adds Two Numbers in PyTorch"><meta name=twitter:description content="writing a nn that adds two numbers in pytorch and comparing with the first response of flagship AI models"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Neural Network Intuition: A Neural Network that Adds Two Numbers in PyTorch","item":"http://localhost:1313/posts/add_numbers/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Neural Network Intuition: A Neural Network that Adds Two Numbers in PyTorch","name":"Neural Network Intuition: A Neural Network that Adds Two Numbers in PyTorch","description":"writing a nn that adds two numbers in pytorch and comparing with the first response of flagship AI models","keywords":["neural network","machine learning","pytorch"],"articleBody":"Outline brief intro of why do problems like this to test intuition link to project code a neural net approximates this equation simple addition of 2 numers approximates a simpler equation that is now just about converging the x weights and error what does normalization do go over MSE loss and Adam Optimizer -\u003e link to resources generate the data and train the neural networks (mine, claude, and ) What Function are we Approximating Defining AddNet 1 2 3 4 5 6 7 8 9 10 11 12 13 import torch import torch.nn as nn import numpy as np class AddNet(nn.Module): def __init__(self): super(AddNet, self).__init__() #TODO: explain simple linear equation facilitated self.output = nn.Linear(2, 1) def forward(self, x): return self.output(x) Normalization and Data Generation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def normalize(x): \"\"\"Normalizes input values to range [0,1].\"\"\" return x / 100.0 def denormalize(x): \"\"\"Denormalizes values back to original range.\"\"\" return x * 100.0 def generate_training_data(num_samples): x1 = torch.randint(0, 101, (num_samples, 1), dtype=torch.float32) x2 = torch.randint(0, 101, (num_samples, 1), dtype=torch.float32) inputs = torch.cat((normalize(x1), normalize(x2)), dim=1) targets = normalize(x1 + x2) return inputs, targets Loss Function, Optimizer, and 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def train_add_net(model, num_epochs=500, batch_size=32): criterion = nn.MSELoss() optimizer = torch.optim.Adam(model.parameters(), lr=0.05) inputs, targets = generate_training_data(1000) for epoch in range(num_epochs): idx = torch.randperm(inputs.shape[0])[:batch_size] batch_inputs = inputs[idx] batch_targets = targets[idx] outputs = model(batch_inputs) loss = criterion(outputs, batch_targets) optimizer.zero_grad() loss.backward() optimizer.step() if (epoch + 1) % 100 == 0: print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}') print_weights_and_bias(model) Inference 1 2 3 4 5 6 7 8 9 10 11 def inference(model, x1, x2): model.eval() with torch.no_grad(): x1 = max(0, min(100, int(x1))) x2 = max(0, min(100, int(x2))) x1_norm = normalize(torch.tensor([[float(x1)]], dtype=torch.float32)) x2_norm = normalize(torch.tensor([[float(x2)]], dtype=torch.float32)) inputs = torch.cat((x1_norm, x2_norm), dim=1) predicted_sum_norm = model(inputs) return denormalize(predicted_sum_norm).item() Results 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def batch_test(model, num_samples): print(f\"\\nBatch Testing ({num_samples} samples):\") print(\"-\" * 50) total_percent_error = 0 for _ in range(num_samples): x1 = np.random.randint(0, 101) x2 = np.random.randint(0, 101) predicted_sum = test_addition(model, x1, x2) actual_sum = x1 + x2 percent_error = abs(predicted_sum - actual_sum) / actual_sum * 100 total_percent_error += percent_error average_percent_error = total_percent_error / num_samples print(f\"\\nAverage Percent Error across {num_samples} samples: {average_percent_error:.2f}%\") Flagship AI Model’s Responce to the prompt 1 2 3 4 5 Write a neural network in PyTorch that can add two numbers. Call it AddNet. It should add two whole numbers that are between 0 and 100. Goal 1 is to get it to add two arbitrary whole numbers in a defined range with the lowest possible error. Goal 2 is to keep the neural net and training definitions to be as simple as possible while still accomplishing Goal 1. At each relevant step of your network definition and training, write about why you made the choice to use that \"technique\". ChatGPT-4o’s Atttempt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 import torch import torch.nn as nn import torch.optim as optim import numpy as np # Define the range of input numbers NUM_RANGE = 101 # From 0 to 100 inclusive # Define the AddNet model class AddNet(nn.Module): def __init__(self): super(AddNet, self).__init__() # Simple feedforward network with 1 hidden layer self.fc1 = nn.Linear(2, 10) # 2 inputs (two numbers) -\u003e 10 hidden neurons self.fc2 = nn.Linear(10, 1) # 10 hidden neurons -\u003e 1 output (sum) def forward(self, x): x = torch.relu(self.fc1(x)) # ReLU activation for non-linearity x = self.fc2(x) # No activation for output layer (regression task) return x # Step 1: Initialize the model, loss function, and optimizer model = AddNet() criterion = nn.MSELoss() # Mean Squared Error Loss for regression optimizer = optim.Adam(model.parameters(), lr=0.01) # Adam optimizer for fast convergence # Explain choice of architecture: # - Input: Two numbers as a 2D tensor (e.g., [45, 30]) # - Hidden layer: A small fully connected layer with 10 neurons balances simplicity and capacity # - ReLU: Adds non-linearity to allow the network to learn complex relationships # - Output: Single value (sum), no activation because this is a regression problem # Step 2: Generate training data def generate_data(size): x_data = np.random.randint(0, NUM_RANGE, size=(size, 2)) # Random pairs of integers y_data = np.sum(x_data, axis=1, keepdims=True) # Compute sums return torch.tensor(x_data, dtype=torch.float32), torch.tensor(y_data, dtype=torch.float32) train_x, train_y = generate_data(10000) # Generate 10,000 training examples # Step 3: Train the model epochs = 500 for epoch in range(epochs): optimizer.zero_grad() # Clear gradients predictions = model(train_x) # Forward pass loss = criterion(predictions, train_y) # Compute loss loss.backward() # Backward pass optimizer.step() # Update weights # Print progress if (epoch + 1) % 50 == 0: print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\") # Explain training process: # - Loss: MSE is suitable for regression because it penalizes large errors # - Optimizer: Adam is chosen for its adaptive learning rate and robustness # - Epochs: 500 iterations are enough to converge for this simple task # - Data: 10,000 examples provide sufficient coverage of input space (0 to 100) # Step 4: Test the model test_x, test_y = generate_data(1000) # Generate test data with torch.no_grad(): # No gradient computation during testing test_predictions = model(test_x) test_loss = criterion(test_predictions, test_y) print(f\"Test Loss: {test_loss.item():.4f}\") # Step 5: Demonstrate prediction example = torch.tensor([[23, 45]], dtype=torch.float32) with torch.no_grad(): prediction = model(example).item() print(f\"Prediction for input {example.tolist()}: {prediction:.2f} (Expected: {sum(example.tolist()[0])})\") Claude 3.5 Sonnet’s Attempt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 import torch import torch.nn as nn import torch.optim as optim import numpy as np class AddNet(nn.Module): def __init__(self): super(AddNet, self).__init__() # A simple architecture with two hidden layers self.network = nn.Sequential( nn.Linear(2, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU(), nn.Linear(4, 1) ) def forward(self, x): return self.network(x) # Initialize the model model = AddNet() criterion = nn.MSELoss() optimizer = optim.Adam(model.parameters(), lr=0.01) # Generate training data def generate_data(num_samples=1000): # Generate random numbers between -10 and 10 x1 = np.random.uniform(-10, 10, (num_samples, 1)) x2 = np.random.uniform(-10, 10, (num_samples, 1)) # True sums y = x1 + x2 # Convert to PyTorch tensors X = torch.FloatTensor(np.hstack((x1, x2))) y = torch.FloatTensor(y) return X, y # Training loop def train(epochs=1000): for epoch in range(epochs): X, y = generate_data() # Forward pass optimizer.zero_grad() output = model(X) loss = criterion(output, y) # Backward pass and optimize loss.backward() optimizer.step() if (epoch + 1) % 100 == 0: print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}') # Train the model train() # Test the model def test_addition(x1, x2): model.eval() with torch.no_grad(): input_tensor = torch.FloatTensor([[x1, x2]]) prediction = model(input_tensor) return prediction.item() # Example usage x1, x2 = 5.7, 3.2 predicted_sum = test_addition(x1, x2) actual_sum = x1 + x2 print(f\"\\nTest Result:\") print(f\"Numbers: {x1} + {x2}\") print(f\"Predicted sum: {predicted_sum:.4f}\") print(f\"Actual sum: {actual_sum:.4f}\") print(f\"Error: {abs(predicted_sum - actual_sum):.4f}\") ","wordCount":"1247","inLanguage":"en","image":"http://localhost:1313/%3Cimage%20path/url%3E","datePublished":"2020-09-15T11:30:03Z","dateModified":"2020-09-15T11:30:03Z","author":{"@type":"Person","name":"Jake Henderson"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/add_numbers/"},"publisher":{"@type":"Organization","name":"None() to Some()","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/posts/ title=posts><span>posts</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Neural Network Intuition: A Neural Network that Adds Two Numbers in PyTorch</h1><div class=post-description>writing a nn that adds two numbers in pytorch and comparing with the first response of flagship AI models</div><div class=post-meta><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1247 words&nbsp;·&nbsp;Jake Henderson&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/add_numbers.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=http://localhost:1313/%3Cimage%20path/url%3E alt><p></p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#outline>Outline</a><ul><li><a href=#what-function-are-we-approximating>What Function are we Approximating</a></li><li><a href=#defining-addnet>Defining AddNet</a></li><li><a href=#normalization-and-data-generation>Normalization and Data Generation</a></li><li><a href=#loss-function-optimizer-and>Loss Function, Optimizer, and</a></li><li><a href=#inference>Inference</a></li><li><a href=#results>Results</a></li><li><a href=#flagship-ai-models-responce-to-the-prompt>Flagship AI Model&rsquo;s Responce to the prompt</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=outline>Outline<a hidden class=anchor aria-hidden=true href=#outline>#</a></h2><ul><li>brief intro of why do problems like this to test intuition</li><li>link to project code</li><li>a neural net approximates this equation</li><li>simple addition of 2 numers approximates a simpler equation
that is now just about converging the x weights and error</li><li>what does normalization do</li><li>go over MSE loss and Adam Optimizer -> link to resources</li><li>generate the data and train the neural networks (mine, claude, and )</li></ul><h3 id=what-function-are-we-approximating>What Function are we Approximating<a hidden class=anchor aria-hidden=true href=#what-function-are-we-approximating>#</a></h3><h3 id=defining-addnet>Defining AddNet<a hidden class=anchor aria-hidden=true href=#defining-addnet>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-0-1><a class=lnlinks href=#hl-0-1> 1</a>
</span><span class=lnt id=hl-0-2><a class=lnlinks href=#hl-0-2> 2</a>
</span><span class=lnt id=hl-0-3><a class=lnlinks href=#hl-0-3> 3</a>
</span><span class=lnt id=hl-0-4><a class=lnlinks href=#hl-0-4> 4</a>
</span><span class=lnt id=hl-0-5><a class=lnlinks href=#hl-0-5> 5</a>
</span><span class=lnt id=hl-0-6><a class=lnlinks href=#hl-0-6> 6</a>
</span><span class=lnt id=hl-0-7><a class=lnlinks href=#hl-0-7> 7</a>
</span><span class=lnt id=hl-0-8><a class=lnlinks href=#hl-0-8> 8</a>
</span><span class=lnt id=hl-0-9><a class=lnlinks href=#hl-0-9> 9</a>
</span><span class=lnt id=hl-0-10><a class=lnlinks href=#hl-0-10>10</a>
</span><span class=lnt id=hl-0-11><a class=lnlinks href=#hl-0-11>11</a>
</span><span class=lnt id=hl-0-12><a class=lnlinks href=#hl-0-12>12</a>
</span><span class=lnt id=hl-0-13><a class=lnlinks href=#hl-0-13>13</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>AddNet</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>AddNet</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1>#TODO: explain simple linear equation facilitated</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>output</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>output</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=normalization-and-data-generation>Normalization and Data Generation<a hidden class=anchor aria-hidden=true href=#normalization-and-data-generation>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-1-1><a class=lnlinks href=#hl-1-1> 1</a>
</span><span class=lnt id=hl-1-2><a class=lnlinks href=#hl-1-2> 2</a>
</span><span class=lnt id=hl-1-3><a class=lnlinks href=#hl-1-3> 3</a>
</span><span class=lnt id=hl-1-4><a class=lnlinks href=#hl-1-4> 4</a>
</span><span class=lnt id=hl-1-5><a class=lnlinks href=#hl-1-5> 5</a>
</span><span class=lnt id=hl-1-6><a class=lnlinks href=#hl-1-6> 6</a>
</span><span class=lnt id=hl-1-7><a class=lnlinks href=#hl-1-7> 7</a>
</span><span class=lnt id=hl-1-8><a class=lnlinks href=#hl-1-8> 8</a>
</span><span class=lnt id=hl-1-9><a class=lnlinks href=#hl-1-9> 9</a>
</span><span class=lnt id=hl-1-10><a class=lnlinks href=#hl-1-10>10</a>
</span><span class=lnt id=hl-1-11><a class=lnlinks href=#hl-1-11>11</a>
</span><span class=lnt id=hl-1-12><a class=lnlinks href=#hl-1-12>12</a>
</span><span class=lnt id=hl-1-13><a class=lnlinks href=#hl-1-13>13</a>
</span><span class=lnt id=hl-1-14><a class=lnlinks href=#hl-1-14>14</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>normalize</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Normalizes input values to range [0,1].&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>x</span> <span class=o>/</span> <span class=mf>100.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>denormalize</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Denormalizes values back to original range.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>x</span> <span class=o>*</span> <span class=mf>100.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_training_data</span><span class=p>(</span><span class=n>num_samples</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>x1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>101</span><span class=p>,</span> <span class=p>(</span><span class=n>num_samples</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>x2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>101</span><span class=p>,</span> <span class=p>(</span><span class=n>num_samples</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>inputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>normalize</span><span class=p>(</span><span class=n>x1</span><span class=p>),</span> <span class=n>normalize</span><span class=p>(</span><span class=n>x2</span><span class=p>)),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>targets</span> <span class=o>=</span> <span class=n>normalize</span><span class=p>(</span><span class=n>x1</span> <span class=o>+</span> <span class=n>x2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>targets</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=loss-function-optimizer-and>Loss Function, Optimizer, and<a hidden class=anchor aria-hidden=true href=#loss-function-optimizer-and>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-2-1><a class=lnlinks href=#hl-2-1> 1</a>
</span><span class=lnt id=hl-2-2><a class=lnlinks href=#hl-2-2> 2</a>
</span><span class=lnt id=hl-2-3><a class=lnlinks href=#hl-2-3> 3</a>
</span><span class=lnt id=hl-2-4><a class=lnlinks href=#hl-2-4> 4</a>
</span><span class=lnt id=hl-2-5><a class=lnlinks href=#hl-2-5> 5</a>
</span><span class=lnt id=hl-2-6><a class=lnlinks href=#hl-2-6> 6</a>
</span><span class=lnt id=hl-2-7><a class=lnlinks href=#hl-2-7> 7</a>
</span><span class=lnt id=hl-2-8><a class=lnlinks href=#hl-2-8> 8</a>
</span><span class=lnt id=hl-2-9><a class=lnlinks href=#hl-2-9> 9</a>
</span><span class=lnt id=hl-2-10><a class=lnlinks href=#hl-2-10>10</a>
</span><span class=lnt id=hl-2-11><a class=lnlinks href=#hl-2-11>11</a>
</span><span class=lnt id=hl-2-12><a class=lnlinks href=#hl-2-12>12</a>
</span><span class=lnt id=hl-2-13><a class=lnlinks href=#hl-2-13>13</a>
</span><span class=lnt id=hl-2-14><a class=lnlinks href=#hl-2-14>14</a>
</span><span class=lnt id=hl-2-15><a class=lnlinks href=#hl-2-15>15</a>
</span><span class=lnt id=hl-2-16><a class=lnlinks href=#hl-2-16>16</a>
</span><span class=lnt id=hl-2-17><a class=lnlinks href=#hl-2-17>17</a>
</span><span class=lnt id=hl-2-18><a class=lnlinks href=#hl-2-18>18</a>
</span><span class=lnt id=hl-2-19><a class=lnlinks href=#hl-2-19>19</a>
</span><span class=lnt id=hl-2-20><a class=lnlinks href=#hl-2-20>20</a>
</span><span class=lnt id=hl-2-21><a class=lnlinks href=#hl-2-21>21</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_add_net</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>num_epochs</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MSELoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.05</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>inputs</span><span class=p>,</span> <span class=n>targets</span> <span class=o>=</span> <span class=n>generate_training_data</span><span class=p>(</span><span class=mi>1000</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randperm</span><span class=p>(</span><span class=n>inputs</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>])[:</span><span class=n>batch_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_inputs</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_targets</span> <span class=o>=</span> <span class=n>targets</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch_inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>batch_targets</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Epoch [</span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s1>], Loss: </span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>print_weights_and_bias</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=inference>Inference<a hidden class=anchor aria-hidden=true href=#inference>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-3-1><a class=lnlinks href=#hl-3-1> 1</a>
</span><span class=lnt id=hl-3-2><a class=lnlinks href=#hl-3-2> 2</a>
</span><span class=lnt id=hl-3-3><a class=lnlinks href=#hl-3-3> 3</a>
</span><span class=lnt id=hl-3-4><a class=lnlinks href=#hl-3-4> 4</a>
</span><span class=lnt id=hl-3-5><a class=lnlinks href=#hl-3-5> 5</a>
</span><span class=lnt id=hl-3-6><a class=lnlinks href=#hl-3-6> 6</a>
</span><span class=lnt id=hl-3-7><a class=lnlinks href=#hl-3-7> 7</a>
</span><span class=lnt id=hl-3-8><a class=lnlinks href=#hl-3-8> 8</a>
</span><span class=lnt id=hl-3-9><a class=lnlinks href=#hl-3-9> 9</a>
</span><span class=lnt id=hl-3-10><a class=lnlinks href=#hl-3-10>10</a>
</span><span class=lnt id=hl-3-11><a class=lnlinks href=#hl-3-11>11</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>inference</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>x1</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=nb>min</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=n>x1</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=n>x2</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=nb>min</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=n>x2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>x1_norm</span> <span class=o>=</span> <span class=n>normalize</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=nb>float</span><span class=p>(</span><span class=n>x1</span><span class=p>)]],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>x2_norm</span> <span class=o>=</span> <span class=n>normalize</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=nb>float</span><span class=p>(</span><span class=n>x2</span><span class=p>)]],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>inputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>x1_norm</span><span class=p>,</span> <span class=n>x2_norm</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>predicted_sum_norm</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>denormalize</span><span class=p>(</span><span class=n>predicted_sum_norm</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-4-1><a class=lnlinks href=#hl-4-1> 1</a>
</span><span class=lnt id=hl-4-2><a class=lnlinks href=#hl-4-2> 2</a>
</span><span class=lnt id=hl-4-3><a class=lnlinks href=#hl-4-3> 3</a>
</span><span class=lnt id=hl-4-4><a class=lnlinks href=#hl-4-4> 4</a>
</span><span class=lnt id=hl-4-5><a class=lnlinks href=#hl-4-5> 5</a>
</span><span class=lnt id=hl-4-6><a class=lnlinks href=#hl-4-6> 6</a>
</span><span class=lnt id=hl-4-7><a class=lnlinks href=#hl-4-7> 7</a>
</span><span class=lnt id=hl-4-8><a class=lnlinks href=#hl-4-8> 8</a>
</span><span class=lnt id=hl-4-9><a class=lnlinks href=#hl-4-9> 9</a>
</span><span class=lnt id=hl-4-10><a class=lnlinks href=#hl-4-10>10</a>
</span><span class=lnt id=hl-4-11><a class=lnlinks href=#hl-4-11>11</a>
</span><span class=lnt id=hl-4-12><a class=lnlinks href=#hl-4-12>12</a>
</span><span class=lnt id=hl-4-13><a class=lnlinks href=#hl-4-13>13</a>
</span><span class=lnt id=hl-4-14><a class=lnlinks href=#hl-4-14>14</a>
</span><span class=lnt id=hl-4-15><a class=lnlinks href=#hl-4-15>15</a>
</span><span class=lnt id=hl-4-16><a class=lnlinks href=#hl-4-16>16</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>batch_test</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>num_samples</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Batch Testing (</span><span class=si>{</span><span class=n>num_samples</span><span class=si>}</span><span class=s2> samples):&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;-&#34;</span> <span class=o>*</span> <span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>total_percent_error</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_samples</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>101</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>101</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>predicted_sum</span> <span class=o>=</span> <span class=n>test_addition</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>actual_sum</span> <span class=o>=</span> <span class=n>x1</span> <span class=o>+</span> <span class=n>x2</span>
</span></span><span class=line><span class=cl>        <span class=n>percent_error</span> <span class=o>=</span> <span class=nb>abs</span><span class=p>(</span><span class=n>predicted_sum</span> <span class=o>-</span> <span class=n>actual_sum</span><span class=p>)</span> <span class=o>/</span> <span class=n>actual_sum</span> <span class=o>*</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>        <span class=n>total_percent_error</span> <span class=o>+=</span> <span class=n>percent_error</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>average_percent_error</span> <span class=o>=</span> <span class=n>total_percent_error</span> <span class=o>/</span> <span class=n>num_samples</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Average Percent Error across </span><span class=si>{</span><span class=n>num_samples</span><span class=si>}</span><span class=s2> samples: </span><span class=si>{</span><span class=n>average_percent_error</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=flagship-ai-models-responce-to-the-prompt>Flagship AI Model&rsquo;s Responce to the prompt<a hidden class=anchor aria-hidden=true href=#flagship-ai-models-responce-to-the-prompt>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-5-1><a class=lnlinks href=#hl-5-1>1</a>
</span><span class=lnt id=hl-5-2><a class=lnlinks href=#hl-5-2>2</a>
</span><span class=lnt id=hl-5-3><a class=lnlinks href=#hl-5-3>3</a>
</span><span class=lnt id=hl-5-4><a class=lnlinks href=#hl-5-4>4</a>
</span><span class=lnt id=hl-5-5><a class=lnlinks href=#hl-5-5>5</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-zed data-lang=zed><span class=line><span class=cl><span class=n>Write</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=n>neural</span><span class=w> </span><span class=n>network</span><span class=w> </span><span class=n>in</span><span class=w> </span><span class=n>PyTorch</span><span class=w> </span><span class=n>that</span><span class=w> </span><span class=n>can</span><span class=w> </span><span class=n>add</span><span class=w> </span><span class=n>two</span><span class=w> </span><span class=n>numbers</span><span class=p>.</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>Call</span><span class=w> </span><span class=n>it</span><span class=w> </span><span class=n>AddNet</span><span class=p>.</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>It</span><span class=w> </span><span class=n>should</span><span class=w> </span><span class=n>add</span><span class=w> </span><span class=n>two</span><span class=w> </span><span class=n>whole</span><span class=w> </span><span class=n>numbers</span><span class=w> </span><span class=n>that</span><span class=w> </span><span class=n>are</span><span class=w> </span><span class=n>between</span><span class=w> </span><span class=err>0</span><span class=w> </span><span class=n>and</span><span class=w> </span><span class=err>100</span><span class=p>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>Goal</span><span class=w> </span><span class=err>1</span><span class=w> </span><span class=n>is</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>get</span><span class=w> </span><span class=n>it</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>add</span><span class=w> </span><span class=n>two</span><span class=w> </span><span class=n>arbitrary</span><span class=w> </span><span class=n>whole</span><span class=w> </span><span class=n>numbers</span><span class=w> </span><span class=n>in</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=n>defined</span><span class=w> </span><span class=n>range</span><span class=w> </span><span class=n>with</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>lowest</span><span class=w> </span><span class=n>possible</span><span class=w> </span><span class=n>error</span><span class=p>.</span><span class=w> </span><span class=n>Goal</span><span class=w> </span><span class=err>2</span><span class=w> </span><span class=n>is</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>keep</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>neural</span><span class=w> </span><span class=n>net</span><span class=w> </span><span class=n>and</span><span class=w> </span><span class=n>training</span><span class=w> </span><span class=n>definitions</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>be</span><span class=w> </span><span class=n>as</span><span class=w> </span><span class=n>simple</span><span class=w> </span><span class=n>as</span><span class=w> </span><span class=n>possible</span><span class=w> </span><span class=n>while</span><span class=w> </span><span class=n>still</span><span class=w> </span><span class=n>accomplishing</span><span class=w> </span><span class=n>Goal</span><span class=w> </span><span class=err>1</span><span class=p>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>At</span><span class=w> </span><span class=n>each</span><span class=w> </span><span class=n>relevant</span><span class=w> </span><span class=n>step</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>your</span><span class=w> </span><span class=n>network</span><span class=w> </span><span class=kt>definition</span><span class=w> </span><span class=n>and</span><span class=w> </span><span class=n>training</span><span class=p>,</span><span class=w> </span><span class=n>write</span><span class=w> </span><span class=n>about</span><span class=w> </span><span class=n>why</span><span class=w> </span><span class=n>you</span><span class=w> </span><span class=n>made</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>choice</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>use</span><span class=w> </span><span class=n>that</span><span class=w> </span><span class=err>&#34;</span><span class=n>technique</span><span class=err>&#34;</span><span class=p>.</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><h6 id=chatgpt-4os-atttempt>ChatGPT-4o&rsquo;s Atttempt<a hidden class=anchor aria-hidden=true href=#chatgpt-4os-atttempt>#</a></h6><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-6-1><a class=lnlinks href=#hl-6-1> 1</a>
</span><span class=lnt id=hl-6-2><a class=lnlinks href=#hl-6-2> 2</a>
</span><span class=lnt id=hl-6-3><a class=lnlinks href=#hl-6-3> 3</a>
</span><span class=lnt id=hl-6-4><a class=lnlinks href=#hl-6-4> 4</a>
</span><span class=lnt id=hl-6-5><a class=lnlinks href=#hl-6-5> 5</a>
</span><span class=lnt id=hl-6-6><a class=lnlinks href=#hl-6-6> 6</a>
</span><span class=lnt id=hl-6-7><a class=lnlinks href=#hl-6-7> 7</a>
</span><span class=lnt id=hl-6-8><a class=lnlinks href=#hl-6-8> 8</a>
</span><span class=lnt id=hl-6-9><a class=lnlinks href=#hl-6-9> 9</a>
</span><span class=lnt id=hl-6-10><a class=lnlinks href=#hl-6-10>10</a>
</span><span class=lnt id=hl-6-11><a class=lnlinks href=#hl-6-11>11</a>
</span><span class=lnt id=hl-6-12><a class=lnlinks href=#hl-6-12>12</a>
</span><span class=lnt id=hl-6-13><a class=lnlinks href=#hl-6-13>13</a>
</span><span class=lnt id=hl-6-14><a class=lnlinks href=#hl-6-14>14</a>
</span><span class=lnt id=hl-6-15><a class=lnlinks href=#hl-6-15>15</a>
</span><span class=lnt id=hl-6-16><a class=lnlinks href=#hl-6-16>16</a>
</span><span class=lnt id=hl-6-17><a class=lnlinks href=#hl-6-17>17</a>
</span><span class=lnt id=hl-6-18><a class=lnlinks href=#hl-6-18>18</a>
</span><span class=lnt id=hl-6-19><a class=lnlinks href=#hl-6-19>19</a>
</span><span class=lnt id=hl-6-20><a class=lnlinks href=#hl-6-20>20</a>
</span><span class=lnt id=hl-6-21><a class=lnlinks href=#hl-6-21>21</a>
</span><span class=lnt id=hl-6-22><a class=lnlinks href=#hl-6-22>22</a>
</span><span class=lnt id=hl-6-23><a class=lnlinks href=#hl-6-23>23</a>
</span><span class=lnt id=hl-6-24><a class=lnlinks href=#hl-6-24>24</a>
</span><span class=lnt id=hl-6-25><a class=lnlinks href=#hl-6-25>25</a>
</span><span class=lnt id=hl-6-26><a class=lnlinks href=#hl-6-26>26</a>
</span><span class=lnt id=hl-6-27><a class=lnlinks href=#hl-6-27>27</a>
</span><span class=lnt id=hl-6-28><a class=lnlinks href=#hl-6-28>28</a>
</span><span class=lnt id=hl-6-29><a class=lnlinks href=#hl-6-29>29</a>
</span><span class=lnt id=hl-6-30><a class=lnlinks href=#hl-6-30>30</a>
</span><span class=lnt id=hl-6-31><a class=lnlinks href=#hl-6-31>31</a>
</span><span class=lnt id=hl-6-32><a class=lnlinks href=#hl-6-32>32</a>
</span><span class=lnt id=hl-6-33><a class=lnlinks href=#hl-6-33>33</a>
</span><span class=lnt id=hl-6-34><a class=lnlinks href=#hl-6-34>34</a>
</span><span class=lnt id=hl-6-35><a class=lnlinks href=#hl-6-35>35</a>
</span><span class=lnt id=hl-6-36><a class=lnlinks href=#hl-6-36>36</a>
</span><span class=lnt id=hl-6-37><a class=lnlinks href=#hl-6-37>37</a>
</span><span class=lnt id=hl-6-38><a class=lnlinks href=#hl-6-38>38</a>
</span><span class=lnt id=hl-6-39><a class=lnlinks href=#hl-6-39>39</a>
</span><span class=lnt id=hl-6-40><a class=lnlinks href=#hl-6-40>40</a>
</span><span class=lnt id=hl-6-41><a class=lnlinks href=#hl-6-41>41</a>
</span><span class=lnt id=hl-6-42><a class=lnlinks href=#hl-6-42>42</a>
</span><span class=lnt id=hl-6-43><a class=lnlinks href=#hl-6-43>43</a>
</span><span class=lnt id=hl-6-44><a class=lnlinks href=#hl-6-44>44</a>
</span><span class=lnt id=hl-6-45><a class=lnlinks href=#hl-6-45>45</a>
</span><span class=lnt id=hl-6-46><a class=lnlinks href=#hl-6-46>46</a>
</span><span class=lnt id=hl-6-47><a class=lnlinks href=#hl-6-47>47</a>
</span><span class=lnt id=hl-6-48><a class=lnlinks href=#hl-6-48>48</a>
</span><span class=lnt id=hl-6-49><a class=lnlinks href=#hl-6-49>49</a>
</span><span class=lnt id=hl-6-50><a class=lnlinks href=#hl-6-50>50</a>
</span><span class=lnt id=hl-6-51><a class=lnlinks href=#hl-6-51>51</a>
</span><span class=lnt id=hl-6-52><a class=lnlinks href=#hl-6-52>52</a>
</span><span class=lnt id=hl-6-53><a class=lnlinks href=#hl-6-53>53</a>
</span><span class=lnt id=hl-6-54><a class=lnlinks href=#hl-6-54>54</a>
</span><span class=lnt id=hl-6-55><a class=lnlinks href=#hl-6-55>55</a>
</span><span class=lnt id=hl-6-56><a class=lnlinks href=#hl-6-56>56</a>
</span><span class=lnt id=hl-6-57><a class=lnlinks href=#hl-6-57>57</a>
</span><span class=lnt id=hl-6-58><a class=lnlinks href=#hl-6-58>58</a>
</span><span class=lnt id=hl-6-59><a class=lnlinks href=#hl-6-59>59</a>
</span><span class=lnt id=hl-6-60><a class=lnlinks href=#hl-6-60>60</a>
</span><span class=lnt id=hl-6-61><a class=lnlinks href=#hl-6-61>61</a>
</span><span class=lnt id=hl-6-62><a class=lnlinks href=#hl-6-62>62</a>
</span><span class=lnt id=hl-6-63><a class=lnlinks href=#hl-6-63>63</a>
</span><span class=lnt id=hl-6-64><a class=lnlinks href=#hl-6-64>64</a>
</span><span class=lnt id=hl-6-65><a class=lnlinks href=#hl-6-65>65</a>
</span><span class=lnt id=hl-6-66><a class=lnlinks href=#hl-6-66>66</a>
</span><span class=lnt id=hl-6-67><a class=lnlinks href=#hl-6-67>67</a>
</span><span class=lnt id=hl-6-68><a class=lnlinks href=#hl-6-68>68</a>
</span><span class=lnt id=hl-6-69><a class=lnlinks href=#hl-6-69>69</a>
</span><span class=lnt id=hl-6-70><a class=lnlinks href=#hl-6-70>70</a>
</span><span class=lnt id=hl-6-71><a class=lnlinks href=#hl-6-71>71</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define the range of input numbers</span>
</span></span><span class=line><span class=cl><span class=n>NUM_RANGE</span> <span class=o>=</span> <span class=mi>101</span>  <span class=c1># From 0 to 100 inclusive</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define the AddNet model</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>AddNet</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>AddNet</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># Simple feedforward network with 1 hidden layer</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>  <span class=c1># 2 inputs (two numbers) -&gt; 10 hidden neurons</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>  <span class=c1># 10 hidden neurons -&gt; 1 output (sum)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>  <span class=c1># ReLU activation for non-linearity</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># No activation for output layer (regression task)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Step 1: Initialize the model, loss function, and optimizer</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AddNet</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MSELoss</span><span class=p>()</span>  <span class=c1># Mean Squared Error Loss for regression</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>)</span>  <span class=c1># Adam optimizer for fast convergence</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Explain choice of architecture:</span>
</span></span><span class=line><span class=cl><span class=c1># - Input: Two numbers as a 2D tensor (e.g., [45, 30])</span>
</span></span><span class=line><span class=cl><span class=c1># - Hidden layer: A small fully connected layer with 10 neurons balances simplicity and capacity</span>
</span></span><span class=line><span class=cl><span class=c1># - ReLU: Adds non-linearity to allow the network to learn complex relationships</span>
</span></span><span class=line><span class=cl><span class=c1># - Output: Single value (sum), no activation because this is a regression problem</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Step 2: Generate training data</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_data</span><span class=p>(</span><span class=n>size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>x_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>NUM_RANGE</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>  <span class=c1># Random pairs of integers</span>
</span></span><span class=line><span class=cl>    <span class=n>y_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>x_data</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdims</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>  <span class=c1># Compute sums</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>x_data</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>y_data</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train_x</span><span class=p>,</span> <span class=n>train_y</span> <span class=o>=</span> <span class=n>generate_data</span><span class=p>(</span><span class=mi>10000</span><span class=p>)</span>  <span class=c1># Generate 10,000 training examples</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Step 3: Train the model</span>
</span></span><span class=line><span class=cl><span class=n>epochs</span> <span class=o>=</span> <span class=mi>500</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>  <span class=c1># Clear gradients</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>train_x</span><span class=p>)</span>  <span class=c1># Forward pass</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>train_y</span><span class=p>)</span>  <span class=c1># Compute loss</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>  <span class=c1># Backward pass</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>  <span class=c1># Update weights</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Print progress</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=mi>50</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Epoch [</span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>epochs</span><span class=si>}</span><span class=s2>], Loss: </span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Explain training process:</span>
</span></span><span class=line><span class=cl><span class=c1># - Loss: MSE is suitable for regression because it penalizes large errors</span>
</span></span><span class=line><span class=cl><span class=c1># - Optimizer: Adam is chosen for its adaptive learning rate and robustness</span>
</span></span><span class=line><span class=cl><span class=c1># - Epochs: 500 iterations are enough to converge for this simple task</span>
</span></span><span class=line><span class=cl><span class=c1># - Data: 10,000 examples provide sufficient coverage of input space (0 to 100)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Step 4: Test the model</span>
</span></span><span class=line><span class=cl><span class=n>test_x</span><span class=p>,</span> <span class=n>test_y</span> <span class=o>=</span> <span class=n>generate_data</span><span class=p>(</span><span class=mi>1000</span><span class=p>)</span>  <span class=c1># Generate test data</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>  <span class=c1># No gradient computation during testing</span>
</span></span><span class=line><span class=cl>    <span class=n>test_predictions</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>test_x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>test_loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>test_predictions</span><span class=p>,</span> <span class=n>test_y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Test Loss: </span><span class=si>{</span><span class=n>test_loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Step 5: Demonstrate prediction</span>
</span></span><span class=line><span class=cl><span class=n>example</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>45</span><span class=p>]],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>prediction</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>example</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Prediction for input </span><span class=si>{</span><span class=n>example</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>prediction</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> (Expected: </span><span class=si>{</span><span class=nb>sum</span><span class=p>(</span><span class=n>example</span><span class=o>.</span><span class=n>tolist</span><span class=p>()[</span><span class=mi>0</span><span class=p>])</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h6 id=claude-35-sonnets-attempt>Claude 3.5 Sonnet&rsquo;s Attempt<a hidden class=anchor aria-hidden=true href=#claude-35-sonnets-attempt>#</a></h6><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-7-1><a class=lnlinks href=#hl-7-1> 1</a>
</span><span class=lnt id=hl-7-2><a class=lnlinks href=#hl-7-2> 2</a>
</span><span class=lnt id=hl-7-3><a class=lnlinks href=#hl-7-3> 3</a>
</span><span class=lnt id=hl-7-4><a class=lnlinks href=#hl-7-4> 4</a>
</span><span class=lnt id=hl-7-5><a class=lnlinks href=#hl-7-5> 5</a>
</span><span class=lnt id=hl-7-6><a class=lnlinks href=#hl-7-6> 6</a>
</span><span class=lnt id=hl-7-7><a class=lnlinks href=#hl-7-7> 7</a>
</span><span class=lnt id=hl-7-8><a class=lnlinks href=#hl-7-8> 8</a>
</span><span class=lnt id=hl-7-9><a class=lnlinks href=#hl-7-9> 9</a>
</span><span class=lnt id=hl-7-10><a class=lnlinks href=#hl-7-10>10</a>
</span><span class=lnt id=hl-7-11><a class=lnlinks href=#hl-7-11>11</a>
</span><span class=lnt id=hl-7-12><a class=lnlinks href=#hl-7-12>12</a>
</span><span class=lnt id=hl-7-13><a class=lnlinks href=#hl-7-13>13</a>
</span><span class=lnt id=hl-7-14><a class=lnlinks href=#hl-7-14>14</a>
</span><span class=lnt id=hl-7-15><a class=lnlinks href=#hl-7-15>15</a>
</span><span class=lnt id=hl-7-16><a class=lnlinks href=#hl-7-16>16</a>
</span><span class=lnt id=hl-7-17><a class=lnlinks href=#hl-7-17>17</a>
</span><span class=lnt id=hl-7-18><a class=lnlinks href=#hl-7-18>18</a>
</span><span class=lnt id=hl-7-19><a class=lnlinks href=#hl-7-19>19</a>
</span><span class=lnt id=hl-7-20><a class=lnlinks href=#hl-7-20>20</a>
</span><span class=lnt id=hl-7-21><a class=lnlinks href=#hl-7-21>21</a>
</span><span class=lnt id=hl-7-22><a class=lnlinks href=#hl-7-22>22</a>
</span><span class=lnt id=hl-7-23><a class=lnlinks href=#hl-7-23>23</a>
</span><span class=lnt id=hl-7-24><a class=lnlinks href=#hl-7-24>24</a>
</span><span class=lnt id=hl-7-25><a class=lnlinks href=#hl-7-25>25</a>
</span><span class=lnt id=hl-7-26><a class=lnlinks href=#hl-7-26>26</a>
</span><span class=lnt id=hl-7-27><a class=lnlinks href=#hl-7-27>27</a>
</span><span class=lnt id=hl-7-28><a class=lnlinks href=#hl-7-28>28</a>
</span><span class=lnt id=hl-7-29><a class=lnlinks href=#hl-7-29>29</a>
</span><span class=lnt id=hl-7-30><a class=lnlinks href=#hl-7-30>30</a>
</span><span class=lnt id=hl-7-31><a class=lnlinks href=#hl-7-31>31</a>
</span><span class=lnt id=hl-7-32><a class=lnlinks href=#hl-7-32>32</a>
</span><span class=lnt id=hl-7-33><a class=lnlinks href=#hl-7-33>33</a>
</span><span class=lnt id=hl-7-34><a class=lnlinks href=#hl-7-34>34</a>
</span><span class=lnt id=hl-7-35><a class=lnlinks href=#hl-7-35>35</a>
</span><span class=lnt id=hl-7-36><a class=lnlinks href=#hl-7-36>36</a>
</span><span class=lnt id=hl-7-37><a class=lnlinks href=#hl-7-37>37</a>
</span><span class=lnt id=hl-7-38><a class=lnlinks href=#hl-7-38>38</a>
</span><span class=lnt id=hl-7-39><a class=lnlinks href=#hl-7-39>39</a>
</span><span class=lnt id=hl-7-40><a class=lnlinks href=#hl-7-40>40</a>
</span><span class=lnt id=hl-7-41><a class=lnlinks href=#hl-7-41>41</a>
</span><span class=lnt id=hl-7-42><a class=lnlinks href=#hl-7-42>42</a>
</span><span class=lnt id=hl-7-43><a class=lnlinks href=#hl-7-43>43</a>
</span><span class=lnt id=hl-7-44><a class=lnlinks href=#hl-7-44>44</a>
</span><span class=lnt id=hl-7-45><a class=lnlinks href=#hl-7-45>45</a>
</span><span class=lnt id=hl-7-46><a class=lnlinks href=#hl-7-46>46</a>
</span><span class=lnt id=hl-7-47><a class=lnlinks href=#hl-7-47>47</a>
</span><span class=lnt id=hl-7-48><a class=lnlinks href=#hl-7-48>48</a>
</span><span class=lnt id=hl-7-49><a class=lnlinks href=#hl-7-49>49</a>
</span><span class=lnt id=hl-7-50><a class=lnlinks href=#hl-7-50>50</a>
</span><span class=lnt id=hl-7-51><a class=lnlinks href=#hl-7-51>51</a>
</span><span class=lnt id=hl-7-52><a class=lnlinks href=#hl-7-52>52</a>
</span><span class=lnt id=hl-7-53><a class=lnlinks href=#hl-7-53>53</a>
</span><span class=lnt id=hl-7-54><a class=lnlinks href=#hl-7-54>54</a>
</span><span class=lnt id=hl-7-55><a class=lnlinks href=#hl-7-55>55</a>
</span><span class=lnt id=hl-7-56><a class=lnlinks href=#hl-7-56>56</a>
</span><span class=lnt id=hl-7-57><a class=lnlinks href=#hl-7-57>57</a>
</span><span class=lnt id=hl-7-58><a class=lnlinks href=#hl-7-58>58</a>
</span><span class=lnt id=hl-7-59><a class=lnlinks href=#hl-7-59>59</a>
</span><span class=lnt id=hl-7-60><a class=lnlinks href=#hl-7-60>60</a>
</span><span class=lnt id=hl-7-61><a class=lnlinks href=#hl-7-61>61</a>
</span><span class=lnt id=hl-7-62><a class=lnlinks href=#hl-7-62>62</a>
</span><span class=lnt id=hl-7-63><a class=lnlinks href=#hl-7-63>63</a>
</span><span class=lnt id=hl-7-64><a class=lnlinks href=#hl-7-64>64</a>
</span><span class=lnt id=hl-7-65><a class=lnlinks href=#hl-7-65>65</a>
</span><span class=lnt id=hl-7-66><a class=lnlinks href=#hl-7-66>66</a>
</span><span class=lnt id=hl-7-67><a class=lnlinks href=#hl-7-67>67</a>
</span><span class=lnt id=hl-7-68><a class=lnlinks href=#hl-7-68>68</a>
</span><span class=lnt id=hl-7-69><a class=lnlinks href=#hl-7-69>69</a>
</span><span class=lnt id=hl-7-70><a class=lnlinks href=#hl-7-70>70</a>
</span><span class=lnt id=hl-7-71><a class=lnlinks href=#hl-7-71>71</a>
</span><span class=lnt id=hl-7-72><a class=lnlinks href=#hl-7-72>72</a>
</span><span class=lnt id=hl-7-73><a class=lnlinks href=#hl-7-73>73</a>
</span><span class=lnt id=hl-7-74><a class=lnlinks href=#hl-7-74>74</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>AddNet</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>AddNet</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># A simple architecture with two hidden layers</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>network</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>8</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>4</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>network</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the model</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AddNet</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MSELoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Generate training data</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_data</span><span class=p>(</span><span class=n>num_samples</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Generate random numbers between -10 and 10</span>
</span></span><span class=line><span class=cl>    <span class=n>x1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=p>(</span><span class=n>num_samples</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>x2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=p>(</span><span class=n>num_samples</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=c1># True sums</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>x1</span> <span class=o>+</span> <span class=n>x2</span>
</span></span><span class=line><span class=cl>    <span class=c1># Convert to PyTorch tensors</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>FloatTensor</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>hstack</span><span class=p>((</span><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>FloatTensor</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Training loop</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train</span><span class=p>(</span><span class=n>epochs</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>generate_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># Forward pass</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># Backward pass and optimize</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Epoch [</span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=n>epochs</span><span class=si>}</span><span class=s1>], Loss: </span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s1>.6f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Train the model</span>
</span></span><span class=line><span class=cl><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Test the model</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_addition</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>input_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>FloatTensor</span><span class=p>([[</span><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>        <span class=n>prediction</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>input_tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>prediction</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Example usage</span>
</span></span><span class=line><span class=cl><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span> <span class=o>=</span> <span class=mf>5.7</span><span class=p>,</span> <span class=mf>3.2</span>
</span></span><span class=line><span class=cl><span class=n>predicted_sum</span> <span class=o>=</span> <span class=n>test_addition</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>actual_sum</span> <span class=o>=</span> <span class=n>x1</span> <span class=o>+</span> <span class=n>x2</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Test Result:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Numbers: </span><span class=si>{</span><span class=n>x1</span><span class=si>}</span><span class=s2> + </span><span class=si>{</span><span class=n>x2</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Predicted sum: </span><span class=si>{</span><span class=n>predicted_sum</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Actual sum: </span><span class=si>{</span><span class=n>actual_sum</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Error: </span><span class=si>{</span><span class=nb>abs</span><span class=p>(</span><span class=n>predicted_sum</span> <span class=o>-</span> <span class=n>actual_sum</span><span class=p>)</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/neural-network/>Neural Network</a></li><li><a href=http://localhost:1313/tags/machine-learning/>Machine Learning</a></li><li><a href=http://localhost:1313/tags/pytorch/>Pytorch</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>None() to Some()</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>